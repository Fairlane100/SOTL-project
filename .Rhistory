setwd("~/Documents/Research Projects/Git Code/SOTL-project")
setwd("~/Documents/Research Projects/Git Code/SOTL-project")
setwd("~/Documents/Research Projects/Git Code/SOTL-project")
newset <- read.csv("Missing compiled cleaned 8-15-16.csv",
stringsAsFactors = FALSE)
source("SOTLutils.R")
infile <- "Missing compiled cleaned 8-15-16.csv
stopfile <- "SOTL-stoplist.csv"
equivfile <- "SOTL-equivalencies.csv"
termConcatfile <- "SOTL-termConcat.csv"
performCleaning(infile,stopfile,equivfile,termConcatfile)
infile <- "Missing compiled cleaned 8-15-16.csv"
stopfile <- "SOTL-stoplist.csv"
equivfile <- "SOTL-equivalencies.csv"
termConcatfile <- "SOTL-termConcat.csv"
performCleaning(infile,stopfile,equivfile,termConcatfile)
View(performCleaning)
View(cleanText)
View(newset)
newset <- read.csv(infile,
stringsAsFactors = FALSE)
SOTLstopwords <- read.csv(stopfile,
stringsAsFactors = FALSE, header = F)$V1
SOTLequivalentWords <- read.csv(equivfile,
stringsAsFactors = FALSE, header = F)
SOTLPhrasesTerms <- read.csv(termConcatfile,
stringsAsFactors = FALSE, header = F)
# defaulted to data.frame.  needs to be in vector form.
SOTLPhrasesTerms <- as.vector(as.matrix(SOTLPhrasesTerms))
c <- orig
# Clean the abstract data before processing
c$abstract <- cleanText(c$abstract,
SOTLstopwords,
SOTLequivalentWords,
SOTLPhrasesTerms)
c <- newset
# Clean the abstract data before processing
c$abstract <- cleanText(c$abstract,
SOTLstopwords,
SOTLequivalentWords,
SOTLPhrasesTerms)
c$abstract <- iconv(c$abstract, "UTF-8", "UTF-8",sub=' ')
# remove short words
c$abstract <- rm_nchar_words(c$abstract, "1,2")
install.packages("rm_nchar_words")
rm_nchar_words::install_github("qdapRegex/R/rm_nchar_words.R")
library ("tm")
install.packages("tm")
library ("tm")
c$abstract <- cleanText(c$abstract,
SOTLstopwords,
SOTLequivalentWords,
SOTLPhrasesTerms)
library(qdap)
library(tm)
#setwd("~/Documents/Research Projects/Git Code/SOTL-project")
newset <- read.csv("Missing compiled cleaned 8-15-16.csv",
stringsAsFactors = FALSE)
source("SOTLutils.R")
infile <- "Missing compiled cleaned 8-15-16.csv"
stopfile <- "SOTL-stoplist.csv"
equivfile <- "SOTL-equivalencies.csv"
termConcatfile <- "SOTL-termConcat.csv"
performCleaning(infile,stopfile,equivfile,termConcatfile)
install("qdap")
install.packages("qdap")
#setwd("~/Documents/Research Projects/Git Code/SOTL-project")
newset <- read.csv("Missing compiled cleaned 8-15-16.csv",
stringsAsFactors = FALSE)
source("SOTLutils.R")
infile <- "Missing compiled cleaned 8-15-16.csv"
stopfile <- "SOTL-stoplist.csv"
equivfile <- "SOTL-equivalencies.csv"
termConcatfile <- "SOTL-termConcat.csv"
performCleaning(infile,stopfile,equivfile,termConcatfile)
tolower
source('~/Documents/Research Projects/Git Code/SOTL-project/SOTLutils.R')
c$abstract <- iconv(c$abstract, "UTF-8", "UTF-8",sub=' ')
#setwd("~/Documents/Research Projects/Git Code/SOTL-project")
newset <- read.csv("Missing compiled cleaned 8-15-16.csv",
stringsAsFactors = FALSE)
source("SOTLutils.R")
infile <- "Missing compiled cleaned 8-15-16.csv"
stopfile <- "SOTL-stoplist.csv"
equivfile <- "SOTL-equivalencies.csv"
termConcatfile <- "SOTL-termConcat.csv"
performCleaning(infile,stopfile,equivfile,termConcatfile)
source('~/Documents/Research Projects/Git Code/SOTL-project/SOTLutils.R')
#setwd("~/Documents/Research Projects/Git Code/SOTL-project")
newset <- read.csv("Missing compiled cleaned 8-15-16.csv",
stringsAsFactors = FALSE)
source("SOTLutils.R")
infile <- "Missing compiled cleaned 8-15-16.csv"
stopfile <- "SOTL-stoplist.csv"
equivfile <- "SOTL-equivalencies.csv"
termConcatfile <- "SOTL-termConcat.csv"
performCleaning(infile,stopfile,equivfile,termConcatfile)
#setwd("~/Documents/Research Projects/Git Code/SOTL-project")
newset <- read.csv("Missing compiled cleaned 8-15-16.csv",
stringsAsFactors = FALSE)
source("SOTLutils.R")
infile <- "Missing compiled cleaned 8-15-16.csv"
stopfile <- "SOTL-stoplist.csv"
equivfile <- "SOTL-equivalencies.csv"
termConcatfile <- "SOTL-termConcat.csv"
performCleaning(infile,stopfile,equivfile,termConcatfile)
source('~/Documents/Research Projects/Git Code/SOTL-project/New article cleaning 8-15-16.R')
source('~/Documents/Research Projects/Git Code/SOTL-project/New article cleaning 8-15-16.R')
source('~/Documents/Research Projects/Git Code/SOTL-project/New article cleaning 8-15-16.R')
# Starting a new run
#setwd("~/Documents/Research Projects/Git Code/SOTL-project")
newset <- read.csv("Missing compiled cleaned 8-15-16.csv",
stringsAsFactors = FALSE)
source("SOTLutils.R")
library(mallet)
infile <- "Missing compiled cleaned 8-15-16.csv"
stopfile <- "SOTL-stoplist.csv"
equivfile <- "SOTL-equivalencies.csv"
termConcatfile <- "SOTL-termConcat.csv"
performCleaning(infile,stopfile,equivfile,termConcatfile)
newwords <- read.csv("Missing compiled cleaned 8-15-16 CLEANED_CULLED.csv")
head("newwords")
view("newwords")
head("newwords")
head(newwords)
dim(newwords)
head(newwords
newwords[1,]
newwordsabstracts.l <- strsplit(newwords.l$abstract, "\\s+")
newwordsabstracts.l <- strsplit(newwordsabstract.l$abstract, "\\s+")
newwordsabstracts.l <- strsplit(newwordsabstracts.l$abstract, "\\s+")
newwordsabstracts <-newwords$abstract
newwordsabstracts.l <- strsplit(newwordsabstracts, "\\s+")
newwordsabstracts <- iconv(newwordsabstracts, "UTF-8", "UTF-8",sub=' ')
newwordsabstracts.l <- strsplit(newwordsabstracts, "\\s+")
chunks.v <- unlist(lapply(newwordsabstracts.l, paste, collapse = " "))
str(ids.v)
str(chunks.v)
summary(nchar(chunks.v))
chunks.v <- unlist(lapply(newwordsabstracts.l, paste, collapse = " "))
str(ids.v)
str(chunks.v)
summary(nchar(chunks.v))
chunks.v <- unlist(lapply(newwordsabstracts.l, paste, collapse = " "))
c$abstract <- iconv(c$abstract, "UTF-8", "UTF-8",sub=' ')
chunks.v
newwordsabstracts.l
class(newwordsabstracts.l)
newwordsabstracts.v <- paste(newwordsabstracts, collapse = " ")
ewwordsabstracts.l <- strsplit(newwordsabstracts.v, "\\s+")
