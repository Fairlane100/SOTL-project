setwd("~/Documents/Research Projects/SOTL field Jen/SOTL R analysis")
importdir <- "Combined clean 6-13-16 CLEANED_CULLED.csv"
output <- "tutorial.mallet"
ntopics <-20
optint <- 20
outputstate <- "topic-state.gz"
outputtopickeys <- "tutorial_leys.txt"
outputdoctopics <- "tutorial_composition.txt"
cd <- "users/jebeatty/Desktop/Mallet-2.0.8RC3"
cd <- "cd /users/jebeatty/Desktop/<allet-2.0.8RC3"
#the above command does not look right.The example for a PC says cd <- "cd C:\\mallet-2.0.7. I am anticipating a problem for the "cd /users" part. I'm also not sure why I am creating a variable named cd, it does not get called in again later?
import <- paste ("bin\\mallet import-dir --input", importdir, "--output", output, "--keep-sequence --remove-stopwords", sep= "")
train ,- paste("bin\\mallet train-topics --input"), output, "--num-topics", ntopics, "--optimize-interval", optint, "--output-state", outputstate, "--output-topic-keys"
import <- paste ("bin\\mallet import-dir --input", importdir, "--output", output, "--keep-sequence --remove-stopwords", sep= " ")
train <- paste("bin\\mallet train-topics --input"), output, "--num-topics", ntopics, "--optimize-interval", optint, "--output-state", outputstate, "--output-topic-keys"
train <- paste("bin\\mallet train-topics --input", output, "--num-topics", ntopics, "--optimize-interval", optint, "--output-state", outputstate, "--output-topic-keys", outputtopickeys, "--output-doc-topics",outputdoctopics, sep = " ")
?mallet.import
library(mallet)
?mallet.import
?mallet.import
getwd
getwd()
setwd("~/Documents/Research Projects/Git Code/SOTL-project")
orig <- read.csv("Combined clean  6-13-16 CLEANED_CULLED.csv",
stringsAsFactors = FALSE)
str(orig)
library(mallet)
source("SOTLutils.R")
source('~/Documents/Research Projects/Git Code/SOTL-project/Sample mallet.R')
source('~/Documents/Research Projects/Git Code/SOTL-project/Sample mallet.R')
str(out)
out1 <- out[[1]]
str(out1)
dim(out1)
out1[1,1:10]
out2 <- out[[2]]
dim(out2)
out2[1,1:10]
str(out2)
?mallet.doc.topics
source('~/Documents/Research Projects/Git Code/SOTL-project/Sample mallet.R')
source('~/Documents/Research Projects/Git Code/SOTL-project/Sample mallet.R')
topic.freqs <- printFrequentTerms(topic.words.df,5)
print(head(topic.freqs))
topic.freqs <- printFrequentTerms(topic.words.df,5)
library(mallet)
numtopics <-20
c <- read.csv("Combined clean 6-13-13 CLEANED_CULLED.csv", stringsAsFactors = FALSE)
setwd("~/Documents/Research Projects/Git Code/SOTL-project")
c <- read.csv("Combined clean 6-13-13 CLEANED_CULLED.csv", stringsAsFactors = FALSE)
library(mallet)
source("SOTLutils.R")
orig <- read.csv("Combined clean  6-13-16 CLEANED_CULLED.csv",
stringsAsFactors = FALSE)
dim(orig)
head(orig, n=3)
help("frequency")
splitorig <- orig
#s <- c[1:5,]
# split each abstract into words
ids.v <- paste(splitorig$journal,splitorig$year,splitorig$Volume.number,splitorig$Issue,splitorig$page,sep="_")
ids.v <- gsub(" ","",ids.v)
words <- splitorig$abstract
words.l <- strsplit(words, "\\s+")
chunks.v <- unlist(lapply(words.l, paste, collapse = " "))
source("SOTL-stoplist primary 7-18-16.csv", "SOTL-equivalencies.csv", "SOTL-termConcat.csv")
dim("SOTL-stoplist primary 7-18-16.csv")
source("SOTL-stoplist primary 7-18-16.csv")
mallet.instances <- mallet.import(ids.v, chunks.v,
"SOTL-stoplist primary 7-18-16.csv", "SOTL-equivalencies.csv", "SOTL-termConcat.csv"
FALSE,
token.regexp = "[\\p{L}']+")
mallet.instances <- mallet.import(ids.v, chunks.v,
"SOTL-stoplist primary 7-18-16.csv",
FALSE,
token.regexp = "[\\p{L}']+")
topic.model <- MalletLDA(num.topics = NUMTOPICS)
topic.model$loadDocuments(mallet.instances)
vocabulary <- topic.model$getVocabulary()
word.freqs <- mallet.word.freqs(topic.model = topic.model)
dim(vocabulary)
vocabulary
length(vocabulary)
word.freqs <- mallet.word.freqs(topic.model = topic.model)
head(word.freqs)
termfreq <-word.freqs[order(word.freqs$term.freq)]
termfreq (1:10,)
head(word.freqs)
termfreq <- word.freqs[order(word.freqs$term.freq)]
word.freqs[order(word.freqs$term.freq)]
termfreqs <- word.freqs [order(word.freqs$term.freq),]
termfreqs[1-10,]
termfreqs[10]
termfreqs[10,]
termfreqs[1-10,]
termfreqs[,1-10]
termfreqs <- word.freqs [order(word.freqs$term.freq),decreasing = TRUE]
termfreqs[1-3,]
termfreqs <- word.freqs [order(word.freqs$term.freq),decreasing = TRUE]
termfreqs <- word.freqs [order(word.freqs$term.freq),decreasing = TRUE,]
head(termfreqs)
head(word.freqs)
length(termfreqs)
orted.wordfreqs.termfreq <- sort (word.freqs$term.freq, decreasing=TRUE)
sorted.wordfreqs.termfreq <- sort (word.freqs$term.freq, decreasing=TRUE)
head(sorted.wordfreqs.termfreq)
str(termfreqs)
str(sorted.wordfreqs.termfreq)
high.freq.terms <- word.freqs [sorted.wordfreqs.termfreq,]
head(high.freq.terms)
sorted.wordfreqs.termfreq <- word.freqs[order(term.freq,doc.freq),]
head(word.freqs)
sorted.wordfreqs.termfreq <- word.freqs[order(term.freq),]
sorted.wordfreqs.termfreq <- word.freqs[order(words),]
sorted.wordfreqs.termfreq[1-5]
str(word.freqs)
str(termfreqs)
install.packages("xlsx")
library("xlsx", lib.loc="~/Library/R/3.3/library")
write.xlsx(x=word.freqs,file = "samplewordfreqs", sheetName = "testsheet", col.names = TRUE, row.names = FALSE, append = FALSE, showNA = TRUE)
write.xlsx(x= word.freqs,file = "samplewordfreqs", sheetName = "testsheet", col.names = TRUE, row.names = FALSE, append = FALSE, showNA = TRUE)
write.xlsx(x= word.freqs,file = "samplewordfreqs.dataframe", sheetName = "testsheet", col.names = TRUE, row.names = FALSE, append = FALSE, showNA = TRUE)
sorted.wordfreqs.termfreq <- sort(word.freqs, decreasing = TRUE)
str(word.freqs)
str(termfreqs)
sorted.wordfreqs.termfreq <- word.freqs[order(word.freqs$term.freq,)]
sorted.wordfreqs.termfreq <- word.freqs[order(word.freqs$term.freq), decreasing = TRUE]
help(order)
sorted.wordfreqs.termfreq <- word.freqs[order(word.freqs$term.freq), decreasing = TRUE,]
sorted.wordfreqs.termfreq <- word.freqs[order(-term.freq), ]
sorted.wordfreqs.termfreq <- word.freqs[order(-$term.freq), ]
sorted.wordfreqs.termfreq <- word.freqs[order(-word.freqs$term.freq), ]
head.matrix(10)
head.matrix(sorted.wordfreqs.termfreq,5)
write(sorted.wordfreqs.termfreq, file ="sorted.wordfreqs.termfreq", ncolumns=3)
View(sorted.wordfreqs.termfreq)
View(sorted.wordfreqs.termfreq)
View(sorted.wordfreqs.termfreq)
save.image("~/Documents/Research Projects/Git Code/SOTL-project/sorted.wordfreqs.termfreqs.RData")
setwd("~/Documents/Research Projects/SOTL field Jen/SOTL R analysis")
write.csv (sorted.wordfreqs.termfreq, file ="sorted.wordfreqs.termfreq",)
sorted.wordfreqs.termfreq <- word.freqs[order(-word.freqs$doc.freq), ]
write.csv (sorted.wordfreqs.termfreq, file ="sorted.wordfreqs.docfreq.csv",)
setwd("~/Documents/Research Projects/Git Code/SOTL-project")
git config -- global user.name "Joy Beatty"
setwd("~/Documents/Research Projects/Git Code/SOTL-project")
str(word.freqs)
str(sorted.wordfreqs.termfreq)
sorted.wordfreqs.termfreq <- word.freqs[order(-word.freqs$term.freq), ]
write.csv (sorted.wordfreqs.termfreq, file ="sorted.wordfreqs.termfreq",)
sorted.wordfreqs.docfreq <- word.freqs[order(-word.freqs$doc.freq), ]
write.csv (sorted.wordfreqs.docfreq, file ="sorted.wordfreqs.docfreq.cs",)
sorted.wordfreqs.docfreq[1-10]
head(sorted.wordfreqs.docfreq,n=10)
head(sorted.wordfreqs.termfreq, n=10)
sorted.wordfreqs.termfreq <- word.freqs[order(-word.freqs$term.freq), ]
write.csv (sorted.wordfreqs.termfreq, file ="sorted.wordfreqs.termfreq.csv",)
sorted.wordfreqs.docfreq <- word.freqs[order(-word.freqs$doc.freq), ]
write.csv (sorted.wordfreqs.docfreq, file ="sorted.wordfreqs.docfreq.csv",)
str(Combined clean 6-13-16 CLEANED_CULLED.csv)
library("Combined clean  6-13-16 CLEANED_CULLED.csv")
str("Combined clean  6-13-16 CLEANED_CULLED.csv")
dim("Combined clean  6-13-16 CLEANED_CULLED.csv")
head("Combined clean  6-13-16 CLEANED_CULLED.csv")
head("Combined clean  6-13-16 CLEANED_CULLED.csv", n=10)
lines("Combined clean  6-13-16 CLEANED_CULLED.csv")
# loading in new cleaned file and running Mallett
# read in the whole csv file for processing
newdata <- read.csv("Combined clean  1-8-16.csv", stringsAsFactors = FALSE)
dim(newdata)
setwd("~/Documents/Research Projects/Git Code/SOTL-project")
# loading in new cleaned file and running Mallett
# read in the whole csv file for processing
setwd("~/Documents/Research Projects/Git Code/SOTL-project")
newdata <- read.csv("Combined clean  1-8-16.csv", stringsAsFactors = FALSE)
dim(newdata)
setwd("~/Documents/Research Projects/Git Code/SOTL-project")
source("Combined clean  8-1-16.csv")
newdata <- read.csv("Combined clean  1-8-16.csv", stringsAsFactors = FALSE)
dim(newdata)
newdata <- read.csv("Combined clean  1-8-16.csv", stringsAsFactors = FALSE)
newdata <- read.csv("Combined clean 8-1-16.csv", stringsAsFactors = FALSE)
dim(newdata)
newdata <- read.csv("Combined clean  8-1-16.csv", stringsAsFactors = FALSE)
dim(newdata)
# remove rows where abstract is NA
# note that I already removed the empty abstracts, so this should not make a difference (running as test)
newdata <- newdata[which(newdata$abstract != ""),]
dim(newdata)
nd < newdata
# split each abstract into words
ids.v <- paste(nd$journal,nd$year,nd$Volume.number,nd$Issue,nd$page,sep="_")
ids.v <- gsub(" ","",ids.v)
words <- nd$abstract
words.lower <- tolower(words)
nd <- newdata
# split each abstract into words
ids.v <- paste(nd$journal,nd$year,nd$Volume.number,nd$Issue,nd$page,sep="_")
ids.v <- gsub(" ","",ids.v)
words <- nd$abstract
words.lower <- tolower(words)
nd <- gsub('(f|ht)tp\\S+\\s*', "", nd)
# remove funky chars that gsub doesnt seem to be able to deal with
old1 <- "äó_„ŽñîÑñîñ"
new1 <- paste(rep(" ",nchar(old1)),collapse = "")
nd <- chartr(old1,new1,nd)
words <- nd$abstract
words.lower <- tolower(words)
dim(newdata)
words.nopunct <- gsub("[^[:alnum:][:space:]']", " ", words)
words.l <- strsplit(words.nopunct, "\\s+")
words.lower <-tolower(words.l)
chunks.v <- unlist(lapply(words.lower, paste, collapse = " "))
str(ids.v)
str(chunks.v)
summary(nchar(chunks.v))
library(mallet)
NUMTOPICS = 12
source("SOTLutils.R")
mallet.instances <- mallet.import(ids.v, chunks.v,
"SOTL-stoplist primary 7-18-16.csv",
FALSE,
token.regexp = "[\\p{L}']+")
topic.model <- MalletLDA(num.topics = NUMTOPICS)
topic.model$loadDocuments(mallet.instances)
vocabulary <- topic.model$getVocabulary()
length(vocabulary)
new.word.freqs <- mallet.word.freqs(topic.model = topic.model)
head(new.word.freqs)
topic.model$train(400)
topic.words.m <- mallet.topic.words(topic.model,
smoothed = TRUE,
normalized = TRUE)
dim(topic.words.m)
colnames(topic.words.m) <- vocabulary
topic.words.m[1-5,12]
View(topic.words.m)
head(topic.words.m)
View(sorted.wordfreqs.docfreq)
